{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import pathlib\n",
    "\n",
    "file_path = pathlib.Path(\"./sample.vdif\").expanduser()\n",
    "VDIF_HEADER_BYTE_SIZE = 32\n",
    "with file_path.open(\"rb\") as f:\n",
    "    header_bytes = f.read(VDIF_HEADER_BYTE_SIZE)\n",
    "    words = struct.unpack(\"<8I\", header_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "from typing import Callable, Sequence\n",
    "\n",
    "Words = Sequence[int]\n",
    "Parser = Callable[[Words], int]\n",
    "\n",
    "\n",
    "def make_parser(word_index: int, bit_index: int, bit_length: int) -> Parser:\n",
    "    \"\"\"Construct a function that converts specific bits from a header.\n",
    "\n",
    "    The function acts on a tuple/array of 32-bits words, extracting given bits\n",
    "    from a specific word and convert then to a integer.\n",
    "    The parameters are those that define header keywords, and the parser do\n",
    "    ``(words[word_index] >> bit_index) & ((1 << bit_length) - 1)``.\n",
    "\n",
    "    Args:\n",
    "        word_index (int): Index into the tuple of words passed to the function.\n",
    "        bit_index (int): Index to the starting bit of the part to be extracted.\n",
    "        bit_length (int): Number of bits to be extracted.\n",
    "\n",
    "    Return:\n",
    "        parser (function): A converter of specific bits from a header.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: It the size of specific bits is less than or equal to 0\n",
    "            or greater than 32.\n",
    "    \"\"\"\n",
    "    if not 0 < bit_index + bit_length <= 32:\n",
    "        raise ValueError(\n",
    "            \"the size of specific bits expected to be greater than 0 and less than 32, \"\n",
    "            f\"got {bit_index + bit_length}\"\n",
    "        )\n",
    "\n",
    "    def parser(words: Words) -> int:\n",
    "        bit_mask = (1 << bit_length) - 1\n",
    "        return (words[word_index] >> bit_index) & bit_mask\n",
    "\n",
    "    return parser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14363767\n"
     ]
    }
   ],
   "source": [
    "class VDIF():\n",
    "    def __init__(self, param):\n",
    "            self.num = param\n",
    "                \n",
    "\n",
    "    def make_parser(self, word_index: int, bit_index: int, bit_length: int) -> Parser:  \n",
    "        def parser(words: Words) -> int:\n",
    "            bit_mask = (1 << bit_length) - 1\n",
    "            return (words[word_index] >> bit_index) & bit_mask\n",
    "        return parser(words)\n",
    "          \n",
    "v = VDIF(14363767)\n",
    "v.make_parser(0, 0, 30)\n",
    "print(v.make_parser(0, 0, 30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('seconds', (0, 0, 30))\n",
      "('legacy', (0, 30, 1))\n",
      "('invalid', (0, 31, 1))\n",
      "('data_frame', (1, 0, 24))\n",
      "('ref_epoch', (1, 24, 6))\n",
      "('unassigned', (1, 30, 2))\n",
      "('data_frame_length', (2, 0, 24))\n",
      "('log_2_channels', (2, 24, 5))\n",
      "('vdif_version', (2, 29, 3))\n",
      "('station', (3, 0, 16))\n",
      "('thread', (3, 16, 10))\n",
      "('bit_sample', (3, 26, 5))\n",
      "('data_type', (3, 31, 1))\n"
     ]
    }
   ],
   "source": [
    "for a in data.items():\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seconds 14363767\n",
      "legacy 0\n",
      "invalid 0\n",
      "data_frame 0\n",
      "ref_epoch 28\n",
      "unassigned 0\n",
      "data_frame_length 629\n",
      "log_2_channels 0\n",
      "vdif_version 1\n",
      "station 65532\n",
      "thread 1\n",
      "bit_sample 1\n",
      "data_type 0\n"
     ]
    }
   ],
   "source": [
    "for key, val in data.items():\n",
    "    print(key, v.make_parser(*val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "class VDIF():\n",
    "    def __init__(self, words):\n",
    "            self.words = words\n",
    "\n",
    "    def make_parser(self, word_index: int, bit_index: int, bit_length: int) -> Parser:  \n",
    "        def parser(words: Words) -> int:\n",
    "            bit_mask = (1 << bit_length) - 1\n",
    "            return (words[word_index] >> bit_index) & bit_mask\n",
    "        return parser(self.words)\n",
    "          \n",
    "v = VDIF(words)\n",
    "v.make_parser(0, 30, 1)\n",
    "print(v.make_parser(0, 30, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14363767,\n",
       " 469762048,\n",
       " 536871541,\n",
       " 67239932,\n",
       " 58720272,\n",
       " 2896953069,\n",
       " 859832320,\n",
       " 4060288387)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seconds 14363767\n",
      "legacy 0\n",
      "invalid 0\n",
      "data_frame 0\n",
      "ref_epoch 28\n",
      "unassigned 0\n",
      "data_frame_length 629\n",
      "log_2_channels 0\n",
      "vdif_version 1\n",
      "station 65532\n",
      "thread 1\n",
      "bit_sample 1\n",
      "data_type 0\n"
     ]
    }
   ],
   "source": [
    "class vdif():\n",
    "    def __init__(self, words):\n",
    "            self.words = words\n",
    "\n",
    "\n",
    "    def make_parser(self, word_index: int, bit_index: int, bit_length: int) -> Parser:  \n",
    "        def parser(words: Words) -> int:\n",
    "            bit_mask = (1 << bit_length) - 1\n",
    "            return (words[word_index] >> bit_index) & bit_mask\n",
    "        return parser(self.words)\n",
    "          \n",
    "v = vdif(words)\n",
    "#v.make_parser(0, 30, 1)\n",
    "#print(v.make_parser(0, 30, 1))\n",
    "\n",
    "data = {\n",
    "    \"seconds\": (0, 0, 30),\n",
    "    \"legacy\": (0, 30, 1),\n",
    "    \"invalid\": (0, 31, 1),\n",
    "    \"data_frame\": (1, 0, 24),\n",
    "    \"ref_epoch\": (1, 24, 6),\n",
    "    \"unassigned\": (1, 30, 2),\n",
    "    \"data_frame_length\": (2, 0, 24),\n",
    "    \"log_2_channels\": (2, 24, 5),\n",
    "    \"vdif_version\": (2, 29, 3),\n",
    "    \"station\": (3, 0, 16),\n",
    "    \"thread\": (3, 16, 10),\n",
    "    \"bit_sample\": (3, 26, 5),\n",
    "    \"data_type\": (3, 31, 1)\n",
    "}\n",
    "for key, val in data.items():\n",
    "    print(key, v.make_parser(*val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-06-16 05:56:07\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "calc_source = datetime.datetime(2000, 1, 1, 0, 0, 0)\n",
    "print(calc_source + relativedelta(years = v.make_parser(*data[\"ref_epoch\"])//2, \n",
    "                                  months = v.make_parser(*data[\"ref_epoch\"]) % 2 * 6,\n",
    "                                  seconds = v.make_parser(*data[\"seconds\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'bit_sample', 'data_frame', 'data_frame_length', 'data_type', 'invalid', 'legacy', 'log_2_channels', 'make_parser', 'ref_epoch', 'seconds', 'station', 'thread', 'unassigned', 'vdif_version']\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'b', 'bit_specs', 'make_parser']\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "class Header():\n",
    "    def __init__(self, bit_specs):\n",
    "       \n",
    "        for key, val in bit_specs.items():\n",
    "            setattr(self, key, self.make_parser(*val))\n",
    "    def make_parser(self, word_index: int, bit_index: int, bit_length: int) -> Parser:  \n",
    "        def parser(words: Words) -> int:\n",
    "            bit_mask = (1 << bit_length) - 1\n",
    "            return (words[word_index] >> bit_index) & bit_mask\n",
    "        return parser(words)    \n",
    "    \n",
    "          \n",
    "            \n",
    "data = Header({\n",
    "        \"seconds\": (0, 0, 30),\n",
    "        \"legacy\": (0, 30, 1),\n",
    "        \"invalid\": (0, 31, 1),\n",
    "        \"data_frame\": (1, 0, 24),\n",
    "        \"ref_epoch\": (1, 24, 6),\n",
    "        \"unassigned\": (1, 30, 2),\n",
    "        \"data_frame_length\": (2, 0, 24),\n",
    "        \"log_2_channels\": (2, 24, 5),\n",
    "        \"vdif_version\": (2, 29, 3),\n",
    "        \"station\": (3, 0, 16),\n",
    "        \"thread\": (3, 16, 10),\n",
    "        \"bit_sample\": (3, 26, 5),\n",
    "        \"data_type\": (3, 31, 1)\n",
    "        })\n",
    "    \n",
    "d = data\n",
    "print(dir(d))\n",
    "print(dir(h))\n",
    "print(d.thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_if', 'dbe_unit', 'edv', 'esb', 'loif_freq', 'major_rev', 'make_parser', 'minor_rev', 'personality type', 'sampling_rate', 'sub band', 'sync pattern', 'ua', 'unit']\n"
     ]
    }
   ],
   "source": [
    "class Header3(Header):\n",
    "    def __init__(self, words):\n",
    "        super(Header3, self).__init__(words)\n",
    "    \n",
    "    \n",
    "data3 = Header3({\n",
    "        \"sampling_rate\": (4, 0, 23),\n",
    "        \"unit\": (4, 23, 1),\n",
    "        \"edv\": (4, 24, 8),\n",
    "        \"sync pattern\": (5, 0, 32),\n",
    "        \"loif_freq\": (6, 0, 32),\n",
    "        \"personality type\": (7, 0, 8),\n",
    "        \"minor_rev\": (7, 8, 4),\n",
    "        \"major_rev\": (7, 12, 4),\n",
    "        \"esb\": (7, 16, 1),\n",
    "        \"sub band\": (7, 17, 3),\n",
    "        \"_if\": (7, 20, 4),\n",
    "        \"dbe_unit\": (7, 24, 4),\n",
    "        \"ua\": (7, 28, 4)\n",
    "})\n",
    "d3 = data3\n",
    "print(d3._if)\n",
    "print(dir(d3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'clear', 'copy', 'fromkeys', 'get', 'items', 'keys', 'pop', 'popitem', 'setdefault', 'update', 'values']\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'data', 'words']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Header' object has no attribute 'thread'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-160-0a430e17a2cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Header' object has no attribute 'thread'"
     ]
    }
   ],
   "source": [
    "class Header():\n",
    "    bit_specs = {\n",
    "        \"seconds\": (0, 0, 30),\n",
    "        \"legacy\": (0, 30, 1),\n",
    "        \"invalid\": (0, 31, 1),\n",
    "        \"data_frame\": (1, 0, 24),\n",
    "        \"ref_epoch\": (1, 24, 6),\n",
    "        \"unassigned\": (1, 30, 2),\n",
    "        \"data_frame_length\": (2, 0, 24),\n",
    "        \"log_2_channels\": (2, 24, 5),\n",
    "        \"vdif_version\": (2, 29, 3),\n",
    "        \"station\": (3, 0, 16),\n",
    "        \"thread\": (3, 16, 10),\n",
    "        \"bit_sample\": (3, 26, 5),\n",
    "        \"data_type\": (3, 31, 1)\n",
    "        }\n",
    "    \n",
    "    def __init__(self, bit_specs):\n",
    "        for key, val in bit_specs.items():\n",
    "            setattr(self, key, self.make_parser(*val))\n",
    "            #self.__setattr__(self, words, self.make_parser(*val))\n",
    "         \n",
    "            \n",
    "    def make_parser(self, word_index: int, bit_index: int, bit_length: int) -> Parser:  \n",
    "        def parser(words: Words) -> int:\n",
    "            bit_mask = (1 << bit_length) - 1\n",
    "            return (words[word_index] >> bit_index) & bit_mask\n",
    "        return parser(words)    \n",
    "                \n",
    "\n",
    "    \n",
    "b = bit_specs\n",
    "print(dir(b))\n",
    "print(dir(h))\n",
    "print(h.thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'bit_sample', 'data_frame', 'data_frame_length', 'data_type', 'invalid', 'legacy', 'log_2_channels', 'make_parser', 'ref_epoch', 'seconds', 'station', 'thread', 'unassigned', 'vdif_version']\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'data', 'words']\n",
      "14363767\n"
     ]
    }
   ],
   "source": [
    "class Header():\n",
    "    def __init__(self, bit_specs):\n",
    "       \n",
    "        for key, val in bit_specs.items():\n",
    "            setattr(self, key, self.make_parser(*val))\n",
    "    def make_parser(self, word_index: int, bit_index: int, bit_length: int) -> Parser:  \n",
    "        def parser(words: Words) -> int:\n",
    "            bit_mask = (1 << bit_length) - 1\n",
    "            return (words[word_index] >> bit_index) & bit_mask\n",
    "        return parser(words)    \n",
    "    \n",
    "          \n",
    "            \n",
    "bit_specs = Header({\n",
    "        \"seconds\": (0, 0, 30),\n",
    "        \"legacy\": (0, 30, 1),\n",
    "        \"invalid\": (0, 31, 1),\n",
    "        \"data_frame\": (1, 0, 24),\n",
    "        \"ref_epoch\": (1, 24, 6),\n",
    "        \"unassigned\": (1, 30, 2),\n",
    "        \"data_frame_length\": (2, 0, 24),\n",
    "        \"log_2_channels\": (2, 24, 5),\n",
    "        \"vdif_version\": (2, 29, 3),\n",
    "        \"station\": (3, 0, 16),\n",
    "        \"thread\": (3, 16, 10),\n",
    "        \"bit_sample\": (3, 26, 5),\n",
    "        \"data_type\": (3, 31, 1)\n",
    "        })\n",
    "    \n",
    "b = bit_specs\n",
    "print(dir(d))\n",
    "print(dir(h))\n",
    "print(b.seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'bit_sample', 'data_frame', 'data_frame_length', 'data_type', 'invalid', 'legacy', 'log_2_channels', 'make_parser', 'ref_epoch', 'seconds', 'station', 'thread', 'unassigned', 'vdif_version']\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'b', 'bit_specs', 'make_parser']\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "class Header():\n",
    "    def __init__(self, bit_specs):\n",
    "       \n",
    "        for key, val in bit_specs.items():\n",
    "            setattr(self, key, self.make_parser(*val))\n",
    "    def make_parser(self, word_index: int, bit_index: int, bit_length: int) -> Parser:  \n",
    "        def parser(words: Words) -> int:\n",
    "            bit_mask = (1 << bit_length) - 1\n",
    "            return (words[word_index] >> bit_index) & bit_mask\n",
    "        return parser(words)    \n",
    "    \n",
    "          \n",
    "            \n",
    "data = Header({\n",
    "        \"seconds\": (0, 0, 30),\n",
    "        \"legacy\": (0, 30, 1),\n",
    "        \"invalid\": (0, 31, 1),\n",
    "        \"data_frame\": (1, 0, 24),\n",
    "        \"ref_epoch\": (1, 24, 6),\n",
    "        \"unassigned\": (1, 30, 2),\n",
    "        \"data_frame_length\": (2, 0, 24),\n",
    "        \"log_2_channels\": (2, 24, 5),\n",
    "        \"vdif_version\": (2, 29, 3),\n",
    "        \"station\": (3, 0, 16),\n",
    "        \"thread\": (3, 16, 10),\n",
    "        \"bit_sample\": (3, 26, 5),\n",
    "        \"data_type\": (3, 31, 1)\n",
    "        })\n",
    "    \n",
    "d = data\n",
    "print(dir(d))\n",
    "print(dir(h))\n",
    "print(d.thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "class Header_common():\n",
    "    bit_specs = {\n",
    "        \"seconds\": (0, 0, 30),\n",
    "        \"legacy\": (0, 30, 1),\n",
    "        \"invalid\": (0, 31, 1),\n",
    "        \"data_frame\": (1, 0, 24),\n",
    "        \"ref_epoch\": (1, 24, 6),\n",
    "        \"unassigned\": (1, 30, 2),\n",
    "        \"data_frame_length\": (2, 0, 24),\n",
    "        \"log_2_channels\": (2, 24, 5),\n",
    "        \"vdif_version\": (2, 29, 3),\n",
    "        \"station\": (3, 0, 16),\n",
    "        \"thread\": (3, 16, 10),\n",
    "        \"bit_sample\": (3, 26, 5),\n",
    "        \"data_type\": (3, 31, 1)\n",
    "        }\n",
    "    \n",
    "    def __init__(self):\n",
    "        for key, val in self.bit_specs.items():\n",
    "            self.__setattr__(key, self.make_parser(*val))\n",
    "            #setattr(self, key, self.make_parser(*val))\n",
    "    def make_parser(self, word_index: int, bit_index: int, bit_length: int) -> Parser:  \n",
    "        def parser(words: Words) -> int:\n",
    "            bit_mask = (1 << bit_length) - 1\n",
    "            return (words[word_index] >> bit_index) & bit_mask\n",
    "        return parser(words)\n",
    "    \n",
    "hc = Header_common()\n",
    "#print(dir(h))\n",
    "print(hc.ref_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14363767\n"
     ]
    }
   ],
   "source": [
    "class Header_vdif3(Header_common):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        for key, val in self.vdif3.items():\n",
    "            self.__setattr__(key, self.make_parser(*val)) \n",
    "\n",
    "    \n",
    "    vdif3 = {\n",
    "        \"sampling_rate\": (4, 0, 23),\n",
    "        \"unit\": (4, 23, 1),\n",
    "        \"edv\": (4, 24, 8),\n",
    "        \"sync pattern\": (5, 0, 32),\n",
    "        \"loif_freq\": (6, 0, 32),\n",
    "        \"personality type\": (7, 0, 8),\n",
    "        \"minor_rev\": (7, 8, 4),\n",
    "        \"major_rev\": (7, 12, 4),\n",
    "        \"esb\": (7, 16, 1),\n",
    "        \"sub band\": (7, 17, 3),\n",
    "        \"_if\": (7, 20, 4),\n",
    "        \"dbe_unit\": (7, 24, 4),\n",
    "        \"ua\": (7, 28, 4)\n",
    "        }\n",
    "\n",
    "h3 = Header_vdif3()\n",
    "print(h3.seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
